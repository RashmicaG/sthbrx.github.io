<!DOCTYPE html>
<html lang="en">
<head>
        <title>Store Half Byte-Reverse Indexed - Articles by Daniel Axtens</title>
        <meta charset="utf-8" />
        <link href="https://sthbrx.github.io/atom.xml" type="application/atom+xml" rel="alternate" title="Store Half Byte-Reverse Indexed Full Atom Feed" />
        <link href="https://sthbrx.github.io/rss.xml" type="application/rss+xml" rel="alternate" title="Store Half Byte-Reverse Indexed RSS Feed" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="https://sthbrx.github.io/">Store Half Byte-Reverse Indexed <strong>A Power Technical Blog</strong></a></h1>
        </header><!-- /#banner -->
        <nav id="menu"><ul>
        </ul></nav><!-- /#menu -->
<section id="content">
<h2>Articles by Daniel Axtens</h2>

<ol id="post-list">
        <li><article class="hentry">
                <header> <h2 class="entry-title"><a href="https://sthbrx.github.io/blog/2015/10/12/a-tale-of-two-dockers/" rel="bookmark" title="Permalink to A tale of two Dockers">A tale of two Dockers</a></h2> </header>
                <footer class="post-info">
                    <time class="published" datetime="2015-10-12T14:14:00+11:00"> Mon 12 October 2015 </time>
                    <address class="vcard author">By
                        <a class="url fn" href="https://sthbrx.github.io/author/daniel-axtens.html">Daniel Axtens</a>
                    </address>
                </footer><!-- /.post-info -->
                <div class="entry-content"> <p>(This was published in an internal technical journal last week, and is now being published here. If you already know what Docker is, feel free to skim the first half.)</p>
<p>Docker seems to be the flavour of the month in IT. Most attention is focussed on using Docker for the deployment of production services. But that's not all Docker is good for. Let's explore Docker, and two ways I use it as a software developer.</p>
<p>Docker: what is it?</p>
<p>Docker is essentially a set of tools to deal with <em>containers</em> and <em>images</em>. </p>
<p>To make up an artificial example, say you are developing a web app. You first build an <em>image</em>: a file system which contains the app, and some associated metadata. The app has to run on something, so you also install things like Python or Ruby and all the necessary libraries, usually by installing a minimal Ubuntu and any necessary packages.<sup id="fnref-1"><a class="footnote-ref" href="#fn-1">1</a></sup> You then run the image inside an isolated environment called a <em>container</em>.</p>
<p>You can have multiple containers running the same image, (for example, your web app running across a fleet of servers) and the containers don't affect each other.  Why? Because Docker is designed around the concept of <em>immutability</em>. Containers can write to the image they are running, but the changes are specific to that container, and aren't preserved beyond the life of the container.<sup id="fnref-2"><a class="footnote-ref" href="#fn-2">2</a></sup> Indeed, once built, images can't be changed at all, only rebuilt from scratch.</p>
<p>However, as well as enabling you to easily run multiple copies, another upshot of immutability is that if your web app allows you to upload photos, and you restart the container, your photos will be gone. Your web app needs to be designed to store all of the data outside of the container, sending it to a dedicated database or object store of some sort.</p>
<p>Making your application Docker friendly is significantly more work than just spinning up a virtual machine and installing stuff. So what does all this extra work get you? Three main things: isolation, control and, as mentioned, immutability. </p>
<p><em>Isolation</em> makes containers easy to migrate and deploy, and easy to update. Once an image is built, it can be copied to another system and launched. Isolation also makes it easy to update software your app depends on: you rebuild the image with software updates, and then just deploy it. You don't have to worry about service A relying on version X of a library while service B depends on version Y; it's all self contained. </p>
<p><em>Immutability</em> also helps with upgrades, especially when deploying them across multiple servers. Normally, you would upgrade your app on each server, and have to make sure that every server gets all the same sets of updates. With Docker, you don't upgrade a running container. Instead, you rebuild your Docker image and re-deploy it, and you then know that the same version of everything is running everywhere. This immutability also guards against the situation where you have a number of different servers that are all special snowflakes with their own little tweaks, and you end up with a fractal of complexity.</p>
<p>Finally, Docker offers a lot of <em>control</em> over containers, and for a low performance penalty. Docker containers can have their CPU, memory and network controlled easily, without the overhead of a full virtual machine. This makes it an attractive solution for running untrusted executables.<sup id="fnref-3"><a class="footnote-ref" href="#fn-3">3</a></sup></p>
<p>As an aside: despite the hype, very little of this is actually particularly new. Isolation and control are not new problems. All Unixes, including Linux, support 'chroots'. The name comes from “change root”: the system call changes the processes idea of what the file system root is, making it impossible for it to access things outside of the new designated root directory.  FreeBSD has jails, which are more powerful, Solaris has Zones, and AIX has WPARs. Chroots are fast and low overhead. However, they offer much lower ability to control the use of system resources. At the other end of the scale, virtual machines (which have been around since ancient IBM mainframes) offer isolation much better than Docker, but with a greater performance hit.</p>
<p>Similarly, immutability isn't really new: Heroku and AWS Spot Instances are both built around the model that you get resources in a known, consistent state when you start, but in both cases your changes won't persist. In the development world, modern CI systems like Travis CI also have this immutable or disposable model – and this was originally built on VMs. Indeed, with a little bit of extra work, both chroots and VMs can give the same immutability properties that Docker gives.</p>
<p>The control properties that Docker provides are largely as a result of leveraging some Linux kernel concepts, most notably something called namespaces.</p>
<p>What Docker does well is not something novel, but the engineering feat of bringing together fine-grained control, isolation and immutability, and – importantly – a tool-chain that is easier to use than any of the alternatives. Docker's tool-chain eases a lot of pain points with regards to building containers: it's vastly simpler than chroots, and easier to customise than most VM setups. Docker also has a number of engineering tricks to reduce the disk space overhead of isolation.</p>
<p>So, to summarise: Docker provides a toolkit for isolated, immutable, finely controlled containers to run executables and services.</p>
<h2>Docker in development: why?</h2>
<p>I don't run network services at work; I do performance work. So how do I use Docker?</p>
<p>There are two things I do with Docker: I build PHP 5, and do performance regression testing on PHP 7. They're good case studies of how isolation and immutability provide real benefits in development and testing, and how the Docker tool chain makes life a lot nicer that previous solutions.</p>
<h3>PHP 5 builds</h3>
<p>I use the <em>isolation</em> that Docker provides to make building PHP 5 easier. PHP 5 depends on an old version of Bison, version 2. Ubuntu and Debian long since moved to version 3. There are a few ways I could have solved this:</p>
<ul>
<li>I could just install the old version directly on my system in <code>/usr/local/</code>, and hope everything still works and nothing else picks up Bison 2 when it needs Bison 3. Or I could install it somewhere else and remember to change my path correctly before I build PHP 5.</li>
<li>I could roll a chroot by hand. Even with tools like debootstrap and schroot, working in chroots is a painful process.</li>
<li>I could spin up a virtual machine on one of our development boxes and install the old version on that. That feels like overkill: why should I need to run an entire operating system? Why should I need to copy my source tree over the network to build it?</li>
</ul>
<p>Docker makes it easy to have a self-contained environment that has Bison 2 built from source, and to build my latest source tree in that environment. Why is Docker so much easier?</p>
<p>Firstly, Docker allows me to base my container on an existing container, and there's an online library of containers to build from.<sup id="fnref-4"><a class="footnote-ref" href="#fn-4">4</a></sup> This means I don't have to roll a base image with <code>debootstrap</code> or the RHEL/CentOS/Fedora equivalent.</p>
<p>Secondly, unlike a chroot build process, which ultimately is just copying files around, a docker build process includes the ability to both copy files from the host and <em>run commands</em> in the context of the image. This is defined in a file called a <code>Dockerfile</code>, and is kicked off by a single command: <code>docker build</code>.</p>
<p>So, my PHP 5 build container loads an Ubuntu Vivid base container, uses apt-get to install the compiler, tool-chain and headers required to build PHP 5, then installs old bison from source, copies in the PHP source tree, and builds it. The vast majority of this process – the installation of the compiler, headers and bison, can be cached, so they don't have to be downloaded each time. And once the container finishes building, I have a fully built PHP interpreter ready for me to interact with.</p>
<p>I do, at the moment, rebuild PHP 5 from scratch each time. This is a bit sub-optimal from a performance point of view. I could alleviate this with a Docker volume, which is a way of sharing data persistently between a host and a guest, but I haven't been sufficiently bothered by the speed yet. However, Docker volumes are also quite fiddly, leading to the development of tools like <code>docker compose</code> to deal with them. They also are prone to subtle and difficult to debug permission issues.</p>
<h3>PHP 7 performance regression testing</h3>
<p>The second thing I use docker for takes advantage of the throwaway nature of docker environments to prevent cross-contamination.</p>
<p>PHP 7 is the next big version of PHP, slated to be released quite soon. I care about how that runs on POWER, and I preferably want to know if it suddenly deteriorates (or improves!). I use Docker to build a container with a daily build of PHP 7, and then I run a benchmark in it. This doesn't give me a particularly meaningful absolute number, but it allows me to track progress over time. Building it inside of Docker means that I can be sure that nothing from old runs persists into new runs, thus giving me more reliable data. However, because I do want the timing data I collect to persist, I send it out of the container over the network.</p>
<p>I've now been collecting this data for almost 4 months, and it's plotted below, along with a 5-point moving average. The most notable feature of the graph is a the drop in benchmark time at about the middle. Sure enough, if you look at the PHP repository, you will see that a set of changes to improve PHP performance were merged on July 29: changes submitted by our very own Anton Blanchard.<sup id="fnref-5"><a class="footnote-ref" href="#fn-5">5</a></sup></p>
<p><img alt="Graph of PHP 7 performance over time" src="/images/dja/php7-perf.png"></p>
<h2>Docker pain points</h2>
<p>Docker provides a vastly improved experience over previous solutions, but there are still a few pain points. For example:</p>
<ol>
<li>
<p>Docker was apparently written by people who had no concept that platforms other than x86 exist. This leads to major issues for cross-architectural setups. For instance, Docker identifies images by a name and a revision. For example, <code>ubuntu</code> is the name of an image, and <code>15.04</code> is a revision. There's no ability to specify an architecture. So, how you do specify that you want, say, a 64-bit, little-endian PowerPC build of an image versus an x86 build? There have been a couple of approaches, both of which are pretty bad. You could name the image differently: say <code>ubuntu_ppc64le</code>. You can also just cheat and override the <code>ubuntu</code> name with an architecture specific version. Both of these break some assumptions in the Docker ecosystem and are a pain to work with.</p>
</li>
<li>
<p>Image building is incredibly inflexible. If you have one system that requires a proxy, and one that does not, you need different Dockerfiles. As far as I can tell, there are no simple ways to hook in any changes between systems into a generic Dockerfile. This is largely by design, but it's still really annoying when you have one system behind a firewall and one system out on the public cloud (as I do in the PHP 7 setup).</p>
</li>
<li>
<p>Visibility into a Docker server is poor. You end up with lots of different, anonymous images and dead containers, and you end up needing scripts to clean them up. It's not clear what Docker puts on your file system, or where, or how to interact with it.</p>
</li>
<li>
<p>Docker is still using reasonably new technologies. This leads to occasional weird, obscure and difficult to debug issues.<sup id="fnref-6"><a class="footnote-ref" href="#fn-6">6</a></sup></p>
</li>
</ol>
<h2>Final words</h2>
<p>Docker provides me with a lot of useful tools in software development: both in terms of building and testing. Making use of it requires a certain amount of careful design thought, but when applied thoughtfully it can make life significantly easier.</p>
<div class="footnote">
<hr>
<ol>
<li id="fn-1">
<p>There's some debate about how much stuff from the OS installation you should be using. You need to have key dynamic libraries available, but I would argue that you shouldn't be running long running processes other than your application. You shouldn't, for example, be running a SSH daemon in your container. (The one exception is that you must handle orphaned child processes appropriately: see <a href="https://blog.phusion.nl/2015/01/20/docker-and-the-pid-1-zombie-reaping-problem/">https://blog.phusion.nl/2015/01/20/docker-and-the-pid-1-zombie-reaping-problem/</a>) Considerations like debugging and monitoring the health of docker containers mean that this point of view is not universally shared.&#160;<a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn-2">
<p>Why not simply make them read only? You may be surprised at how many things break when running on a read-only file system. Things like logs and temporary files are common issues.&#160;<a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn-3">
<p>It is, however, easier to escape a Docker container than a VM. In Docker, an untrusted executable only needs a kernel exploit to get to root on the host, whereas in a VM you need a guest-to-host vulnerability, which are much rarer.&#160;<a class="footnote-backref" href="#fnref-3" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
<li id="fn-4">
<p>Anyone can upload an image, so this does require running untrusted code from the Internet. Sadly, this is a distinctly retrograde step when compared to the process of installing binary packages in distros, which are all signed by a distro's private key.&#160;<a class="footnote-backref" href="#fnref-4" title="Jump back to footnote 4 in the text">&#8617;</a></p>
</li>
<li id="fn-5">
<p>See <a href="https://github.com/php/php-src/pull/1326">https://github.com/php/php-src/pull/1326</a>&#160;<a class="footnote-backref" href="#fnref-5" title="Jump back to footnote 5 in the text">&#8617;</a></p>
</li>
<li id="fn-6">
<p>I hit this last week: <a href="https://github.com/docker/docker/issues/16256">https://github.com/docker/docker/issues/16256</a>, although maybe that's my fault for running systemd on my laptop.&#160;<a class="footnote-backref" href="#fnref-6" title="Jump back to footnote 6 in the text">&#8617;</a></p>
</li>
</ol>
</div> </div><!-- /.entry-content -->
        </article></li>
        <li><article class="hentry">
                <header> <h2 class="entry-title"><a href="https://sthbrx.github.io/blog/2015/06/03/ppc64le-hello-on-real-hardware/" rel="bookmark" title="Permalink to Running ppc64le_hello on real hardware">Running ppc64le_hello on real hardware</a></h2> </header>
                <footer class="post-info">
                    <time class="published" datetime="2015-06-03T12:16:00+10:00"> Wed 03 June 2015 </time>
                    <address class="vcard author">By
                        <a class="url fn" href="https://sthbrx.github.io/author/daniel-axtens.html">Daniel Axtens</a>
                    </address>
                </footer><!-- /.post-info -->
                <div class="entry-content"> <p>So today I saw <a href="https://github.com/andreiw/ppc64le_hello">Freestanding “Hello World” for OpenPower</a> on <a href="https://news.ycombinator.com/item?id=9649490">Hacker News</a>. Sadly Andrei hadn't been able to test it on real hardware, so I set out to get it running on a real OpenPOWER box. Here's what I did.</p>
<p>Firstly, clone the repo, and, as mentioned in the README, comment out <code>mambo_write</code>. Build it.</p>
<p>Grab <a href="https://github.com/open-power/op-build">op-build</a>, and build a Habanero defconfig. To save yourself a fair bit of time, first edit <code>openpower/configs/habanero_defconfig</code> to answer <code>n</code> about a custom kernel source. That'll save you hours of waiting for git.</p>
<p>This will build you a PNOR that will boot a linux kernel with Petitboot. This is almost what you want: you need Skiboot, Hostboot and a bunch of the POWER specific bits and bobs, but you don't actually want the Linux boot kernel.</p>
<p>Then, based on <code>op-build/openpower/package/openpower-pnor/openpower-pnor.mk</code>, we look through the output of <code>op-build</code> for a  <code>create_pnor_image.pl</code> command, something like this monstrosity:</p>
<p><code>PATH="/scratch/dja/public/op-build/output/host/bin:/scratch/dja/public/op-build/output/host/sbin:/scratch/dja/public/op-build/output/host/usr/bin:/scratch/dja/public/op-build/output/host/usr/sbin:/home/dja/bin:/home/dja/bin:/home/dja/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/opt/openpower/common/x86_64/bin" /scratch/dja/public/op-build/output/build/openpower-pnor-ed1682e10526ebd85825427fbf397361bb0e34aa/create_pnor_image.pl -xml_layout_file /scratch/dja/public/op-build/output/build/openpower-pnor-ed1682e10526ebd85825427fbf397361bb0e34aa/"defaultPnorLayoutWithGoldenSide.xml" -pnor_filename /scratch/dja/public/op-build/output/host/usr/powerpc64-buildroot-linux-gnu/sysroot/pnor/"habanero.pnor" -hb_image_dir /scratch/dja/public/op-build/output/host/usr/powerpc64-buildroot-linux-gnu/sysroot/hostboot_build_images/ -scratch_dir /scratch/dja/public/op-build/output/host/usr/powerpc64-buildroot-linux-gnu/sysroot/openpower_pnor_scratch/ -outdir /scratch/dja/public/op-build/output/host/usr/powerpc64-buildroot-linux-gnu/sysroot/pnor/ -payload /scratch/dja/public/op-build/output/images/"skiboot.lid" -bootkernel /scratch/dja/public/op-build/output/images/zImage.epapr -sbe_binary_filename "venice_sbe.img.ecc" -sbec_binary_filename "centaur_sbec_pad.img.ecc" -wink_binary_filename "p8.ref_image.hdr.bin.ecc" -occ_binary_filename /scratch/dja/public/op-build/output/host/usr/powerpc64-buildroot-linux-gnu/sysroot/occ/"occ.bin" -targeting_binary_filename "HABANERO_HB.targeting.bin.ecc" -openpower_version_filename /scratch/dja/public/op-build/output/host/usr/powerpc64-buildroot-linux-gnu/sysroot/openpower_version/openpower-pnor.version.txt</code></p>
<p>Replace the <code>-bootkernel</code> arguement with the path to ppc64le_hello, e.g.: <code>-bootkernel /scratch/dja/public/ppc64le_hello/ppc64le_hello</code></p>
<p>Don't forget to move it into place! </p>
<div class="highlight"><pre><span></span>mv output/host/usr/powerpc64-buildroot-linux-gnu/sysroot/pnor/habanero.pnor output/images/habanero.pnor
</pre></div>


<p>Then we can use skiboot's boot test script (written by Cyril and me, coincidentally!) to flash it.</p>
<div class="highlight"><pre><span></span>ppc64le_hello/skiboot/external/boot-tests/boot_test.sh -vp -t hab2-bmc -P &lt;path to&gt;/habanero.pnor
</pre></div>


<p>It's not going to get into Petitboot, so just interrupt it after it powers up the box and connect with IPMI. It boots, kinda:</p>
<div class="highlight"><pre><span></span>[11012941323,5] INIT: Starting kernel at 0x20010000, fdt at 0x3044db68 (size 0x11cc3)
Hello OPAL!
           _start = 0x20010000
                              _bss   = 0x20017E28
                                                 _stack = 0x20018000
                                                                    _end   = 0x2001A000
                                                                                       KPCR   = 0x20017E50
                                                                                                          OPAL   = 0x30000000
                                                                                                                             FDT    = 0x3044DB68
                                                                                                                                                CPU0 not found?

                                                                                                                                                               Pick your poison:
                                                                                                                                                                                Choices: (MMU = disabled):
                                                                                                                                                                                                             (d) 5s delay
                                                                                                                                                                                                                            (e) test exception
    (n) test nested exception
                                (f) dump FDT
                                               (M) enable MMU
                                                                (m) disable MMU
                                                                                  (t) test MMU
                                                                                                 (u) test non-priviledged code
                                                                                                                                 (I) enable ints
                                                                                                                                                   (i) disable ints
                                                                                                                                                                      (H) enable HV dec
                                                                                                                                                                                          (h) disable HV dec
                                                                                                                                                                                                               (q) poweroff
                                                                                                                                                                                                                             1.42486|ERRL|Dumping errors reported prior to registration
</pre></div>


<p>Yes, it does wrap horribly. However, the big issue here (which you'll have to scroll to see!) is the "CPU0 not found?". Fortunately, we can fix this with a little patch to <code>cpu_init</code> in main.c to test for a PowerPC POWER8:</p>
<div class="highlight"><pre><span></span>    <span class="n">cpu0_node</span> <span class="o">=</span> <span class="n">fdt_path_offset</span><span class="p">(</span><span class="n">fdt</span><span class="p">,</span> <span class="s">&quot;/cpus/cpu@0&quot;</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">cpu0_node</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">cpu0_node</span> <span class="o">=</span> <span class="n">fdt_path_offset</span><span class="p">(</span><span class="n">fdt</span><span class="p">,</span> <span class="s">&quot;/cpus/PowerPC,POWER8@20&quot;</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">cpu0_node</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">printk</span><span class="p">(</span><span class="s">&quot;CPU0 not found?</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
        <span class="k">return</span><span class="p">;</span>
    <span class="p">}</span>
</pre></div>


<p>This is definitely the <em>wrong</em> way to do this, but it works for now.</p>
<p>Now, correcting for weird wrapping, we get:</p>
<div class="highlight"><pre><span></span>Hello OPAL!
_start = 0x20010000
_bss   = 0x20017E28
_stack = 0x20018000
_end   = 0x2001A000
KPCR   = 0x20017E50
OPAL   = 0x30000000
FDT    = 0x3044DB68
Assuming default SLB size
SLB size = 0x20
TB freq = 512000000
[13205442015,3] OPAL: Trying a CPU re-init with flags: 0x2
Unrecoverable exception stack top @ 0x20019EC8
HTAB (2048 ptegs, mask 0x7FF, size 0x40000) @ 0x20040000
SLB entries:
1: E 0x8000000 V 0x4000000000000400
EA 0x20040000 -&gt; hash 0x20040 -&gt; pteg 0x200 = RA 0x20040000
EA 0x20041000 -&gt; hash 0x20041 -&gt; pteg 0x208 = RA 0x20041000
EA 0x20042000 -&gt; hash 0x20042 -&gt; pteg 0x210 = RA 0x20042000
EA 0x20043000 -&gt; hash 0x20043 -&gt; pteg 0x218 = RA 0x20043000
EA 0x20044000 -&gt; hash 0x20044 -&gt; pteg 0x220 = RA 0x20044000
EA 0x20045000 -&gt; hash 0x20045 -&gt; pteg 0x228 = RA 0x20045000
EA 0x20046000 -&gt; hash 0x20046 -&gt; pteg 0x230 = RA 0x20046000
EA 0x20047000 -&gt; hash 0x20047 -&gt; pteg 0x238 = RA 0x20047000
EA 0x20048000 -&gt; hash 0x20048 -&gt; pteg 0x240 = RA 0x20048000
...
</pre></div>


<p>The weird wrapping seems to be caused by NULLs getting printed to OPAL, but I haven't traced what causes that.</p>
<p>Anyway, now it largely works! Here's a transcript of some things it can do on real hardware.</p>
<div class="highlight"><pre><span></span>Choices: (MMU = disabled):
   (d) 5s delay
   (e) test exception
   (n) test nested exception
   (f) dump FDT
   (M) enable MMU
   (m) disable MMU
   (t) test MMU
   (u) test non-priviledged code
   (I) enable ints
   (i) disable ints
   (H) enable HV dec
   (h) disable HV dec
   (q) poweroff
&lt;press e&gt;
Testing exception handling...
sc(feed) =&gt; 0xFEEDFACE
Choices: (MMU = disabled):
   (d) 5s delay
   (e) test exception
   (n) test nested exception
   (f) dump FDT
   (M) enable MMU
   (m) disable MMU
   (t) test MMU
   (u) test non-priviledged code
   (I) enable ints
   (i) disable ints
   (H) enable HV dec
   (h) disable HV dec
   (q) poweroff
&lt;press t&gt;
EA 0xFFFFFFF000 -&gt; hash 0xFFFFFFF -&gt; pteg 0x3FF8 = RA 0x20010000
mapped 0xFFFFFFF000 to 0x20010000 correctly
EA 0xFFFFFFF000 -&gt; hash 0xFFFFFFF -&gt; pteg 0x3FF8 = unmap
EA 0xFFFFFFF000 -&gt; hash 0xFFFFFFF -&gt; pteg 0x3FF8 = RA 0x20011000
mapped 0xFFFFFFF000 to 0x20011000 incorrectly
EA 0xFFFFFFF000 -&gt; hash 0xFFFFFFF -&gt; pteg 0x3FF8 = unmap
Choices: (MMU = disabled):
   (d) 5s delay
   (e) test exception
   (n) test nested exception
   (f) dump FDT
   (M) enable MMU
   (m) disable MMU
   (t) test MMU
   (u) test non-priviledged code
   (I) enable ints
   (i) disable ints
   (H) enable HV dec
   (h) disable HV dec
   (q) poweroff
&lt;press u&gt;
EA 0xFFFFFFF000 -&gt; hash 0xFFFFFFF -&gt; pteg 0x3FF8 = RA 0x20080000
returning to user code
returning to kernel code
EA 0xFFFFFFF000 -&gt; hash 0xFFFFFFF -&gt; pteg 0x3FF8 = unmap
</pre></div>


<p>I also tested the other functions and they all seem to work. Running non-priviledged code with the MMU on works. Dumping the FDT and the 5s delay both worked, although they tend to stress IPMI a <em>lot</em>. The delay seems to correspond well with real time as well.</p>
<p>It does tend to error out and reboot quite often, usually on the menu screen, for reasons that are not clear to me. It usually starts with something entirely uninformative from Hostboot, like this:</p>
<div class="highlight"><pre><span></span>1.41801|ERRL|Dumping errors reported prior to registration
  2.89873|Ignoring boot flags, incorrect version 0x0
</pre></div>


<p>That may be easy to fix, but again I haven't had time to trace it.</p>
<p>All in all, it's very exciting to see something come out of the simulator and in to real hardware. Hopefully with the proliferation of OpenPOWER hardware, prices will fall and these sorts of systems will become increasingly accessible to people with cool low level projects like this!</p> </div><!-- /.entry-content -->
        </article></li>
        <li><article class="hentry">
                <header> <h2 class="entry-title"><a href="https://sthbrx.github.io/blog/2015/05/27/joining-the-capi-project/" rel="bookmark" title="Permalink to Joining the CAPI project">Joining the CAPI project</a></h2> </header>
                <footer class="post-info">
                    <time class="published" datetime="2015-05-27T15:08:00+10:00"> Wed 27 May 2015 </time>
                    <address class="vcard author">By
                        <a class="url fn" href="https://sthbrx.github.io/author/daniel-axtens.html">Daniel Axtens</a>
                    </address>
                </footer><!-- /.post-info -->
                <div class="entry-content"> <p>(I wrote this blog post a couple of months ago, but it's still quite relevant.)</p>
<p>Hi, I'm Daniel! I work in OzLabs, part of IBM's Australian Development Labs. Recently, I've been assigned to the CAPI project, and I've been given the opportunity to give you an idea of what this is, and what I'll be up to in the future!</p>
<h2>What even is CAPI?</h2>
<p>To help you understand CAPI, think back to the time before computers. We had a variety of machines: machines to build things, to check things, to count things, but they were all specialised --- good at one and only one thing.</p>
<p>Specialised machines, while great at their intended task, are really expensive to develop. Not only that, it's often impossible to change how they operate, even in very small ways.</p>
<p>Computer processors, on the other hand, are generalists. They are cheap. They can do a lot of things. If you can break a task down into simple steps, it's easy to get them to do it. The trade-off is that computer processors are incredibly inefficient at everything.</p>
<p>Now imagine, if you will, that a specialised machine is a highly trained and experienced professional, a computer processor is a hungover university student.</p>
<p>Over the years, we've tried lots of things to make student faster. Firstly, we gave the student lots of caffeine to make them go as fast as they can. That worked for a while, but you can only give someone so much caffeine before they become unreliable. Then we tried teaming the student up with another student, so they can do two things at once. That worked, so we added more and more students. Unfortunately, lots of tasks can only be done by one person at a time, and team-work is complicated to co-ordinate. We've also recently noticed that some tasks come up often, so we've given them some tools for those specific tasks. Sadly, the tools are only useful for those specific situations.</p>
<p>Sometimes, what you really need is a professional.</p>
<p>However, there are a few difficulties in getting a professional to work with uni students. They don't speak the same way; they don't think the same way, and they don't work the same way. You need to teach the uni students how to work with the professional, and vice versa.</p>
<p>Previously, developing this interface – this connection between a generalist processor and a specialist machine – has been particularly difficult. The interface between processors and these specialised machines – known as <em>accelerators</em> – has also tended to suffer from bottlenecks and inefficiencies.</p>
<p>This is the problem CAPI solves. CAPI provides a simpler and more optimised way to interface specialised hardware accelerators with IBM's most recent line of processors, POWER8. It's a common 'language' that the processor and the accelerator talk, that makes it much easier to build the hardware side and easier to program the software side. In our Canberra lab, we're working primarily on the operating system side of this. We are working with some external companies who are building CAPI devices and the optimised software products which use them.</p>
<p>From a technical point of view, CAPI provides <em>coherent</em> access to system memory and processor caches, eliminating a major bottleneck in using external devices as accelerators. This is illustrated really well by the following graphic from <a href="https://www.youtube.com/watch?v=4ZyXc12J6FA">an IBM promotional video</a>. In the non-CAPI case, you can see there's a lot of data (the little boxes) stalled in the PCIe subsystem, whereas with CAPI, the accelerator has direct access to the memory subsystem, which makes everything go faster.</p>
<p><img alt="Slide showing CAPI's memory access" src="/images/dja/capi-memory.png"></p>
<h2>Uses of CAPI</h2>
<p>CAPI technology is already powering a few really cool products.</p>
<p>Firstly, we have an implementation of Redis that sits on top of flash storage connected over CAPI. Or, to take out the buzzwords, CAPI lets us do really, really fast NoSQL databases. There's <a href="https://www.youtube.com/watch?v=cCmFc_0xsvA">a video online</a> giving more details.</p>
<p>Secondly, our partner <a href="http://www.mellanox.com/page/products_dyn?product_family=201&amp;mtag=connectx_4_vpi_card">Mellanox</a> is using CAPI to make network cards that run at speeds of up to 100Gb/s.</p>
<p>CAPI is also part of IBM's OpenPOWER initiative, where we're trying to grow a community of companies around our POWER system designs. So in many ways, CAPI is both a really cool technology, and a brand new ecosystem that we're growing here in the Canberra labs. It's very cool to be a part of!</p> </div><!-- /.entry-content -->
        </article></li>
</ol><!-- /#posts-list -->
<p class="paginator">
        <a href="https://sthbrx.github.io/author/daniel-axtens2.html">&laquo;</a>
    Page 3 / 3
</p>
</section><!-- /#content -->
        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>,
                which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->
        </footer><!-- /#contentinfo -->
</body>
</html>