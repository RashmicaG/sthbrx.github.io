<!DOCTYPE html>
<html lang="en">
<head>
          <title>Store Half Byte-Reverse Indexed</title>
        <meta charset="utf-8" />
        <link href="https://sthbrx.github.io/atom.xml" type="application/atom+xml" rel="alternate" title="Store Half Byte-Reverse Indexed Full Atom Feed" />
        <link href="https://sthbrx.github.io/rss.xml" type="application/rss+xml" rel="alternate" title="Store Half Byte-Reverse Indexed RSS Feed" />


    <meta name="tags" content="lustre" />
    <meta name="tags" content="hpc" />

</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="https://sthbrx.github.io/">Store Half Byte-Reverse Indexed <strong>A Power Technical Blog</strong></a></h1>
        </header><!-- /#banner -->
        <nav id="menu"><ul>
        </ul></nav><!-- /#menu -->
<section id="content" class="body">
  <header>
    <h2 class="entry-title">
      <a href="https://sthbrx.github.io/blog/2017/02/13/high-power-lustre/" rel="bookmark"
         title="Permalink to High Power Lustre">High Power Lustre</a></h2>
 
  </header>
  <footer class="post-info">
    <time class="published" datetime="2017-02-13T16:29:00+11:00">
      Mon 13 February 2017
    </time>
    <address class="vcard author">
      By           <a class="url fn" href="https://sthbrx.github.io/author/daniel-axtens.html">Daniel Axtens</a>
          <a class="url fn" href="https://sthbrx.github.io/author/rashmica-gupta.html">Rashmica Gupta</a>
    </address>
  </footer><!-- /.post-info -->
  <div class="entry-content">
    <p>(Most of the hard work here was done by fellow blogger Rashmica - I just verified her instructions and wrote up this post.)</p>
<p><a href="http://lustre.org/">Lustre</a> is a high-performance clustered file system. Traditionally the Lustre client and server have run on x86, but both the server and client will also work on Power. Here's how to get them running.</p>
<h1>Server</h1>
<p>Lustre normally requires a patched 'enterprise' kernel - normally an old RHEL, CentOS or SUSE kernel. We tested with a CentOS 7.3 kernel. We tried to follow <a href="https://wiki.hpdd.intel.com/pages/viewpage.action?pageId=52104622">the Intel instructions</a> for building the kernel as much as possible - any deviations we had to make are listed below.</p>
<h2>Setup quirks</h2>
<p>We are told to edit <code>~/kernel/rpmbuild/SPEC/kernel.spec</code>. This doesn't exist because the directory is <code>SPECS</code> not <code>SPEC</code>: you need to edit <code>~/kernel/rpmbuild/SPECS/kernel.spec</code>.</p>
<p>I also found there was an extra quote mark in the supplied patch script after <code>-lustre.patch</code>. I removed that and ran this instead:</p>
<div class="highlight"><pre><span></span>for patch in $(<span class="err">&lt;</span>&quot;3.10-rhel7.series&quot;); do \
      patch_file=&quot;<span class="nv">$HOME</span>/lustre-release/lustre/kernel_patches/patches/<span class="cp">${</span><span class="n">patch</span><span class="cp">}</span>&quot; \
      cat &quot;<span class="cp">${</span><span class="n">patch_file</span><span class="cp">}</span>&quot; &gt;&gt; <span class="nv">$HOME</span>/lustre-kernel-x86_64-lustre.patch \
done
</pre></div>


<p>The fact that there is 'x86_64' in the patch name doesn't matter as you're about to copy it under a different name to a place where it will be included by the spec file.</p>
<h2>Building for ppc64le</h2>
<p>Building for ppc64le was reasonably straight-forward. I had one small issue:</p>
<div class="highlight"><pre><span></span>[build@dja-centos-guest rpmbuild]$ rpmbuild -bp --target=`uname -m` ./SPECS/kernel.spec
Building target platforms: ppc64le
Building for target ppc64le
error: Failed build dependencies:
       net-tools is needed by kernel-3.10.0-327.36.3.el7.ppc64le
</pre></div>


<p>Fixing this was as simple as a <code>yum install net-tools</code>.</p>
<p>This was sufficient to build the kernel RPMs. I installed them and booted to my patched kernel - so far so good!</p>
<h1>Building the client packages: CentOS</h1>
<p>I then tried to build and install the RPMs from <a href="https://git.hpdd.intel.com/?p=fs/lustre-release.git;a=summary"><code>lustre-release</code></a>. This repository provides the sources required to build the client and utility binaries.</p>
<p><code>./configure</code> and <code>make</code> succeeded, but when I went to install the packages with <code>rpm</code>, I found I was missing some dependencies:</p>
<div class="highlight"><pre><span></span><span class="n">error</span><span class="o">:</span> <span class="n">Failed</span> <span class="n">dependencies</span><span class="o">:</span>
        <span class="n">ldiskfsprogs</span> <span class="o">&gt;=</span> <span class="mf">1.42</span><span class="o">.</span><span class="mi">7</span><span class="o">.</span><span class="na">wc1</span> <span class="k">is</span> <span class="n">needed</span> <span class="n">by</span> <span class="n">kmod</span><span class="o">-</span><span class="n">lustre</span><span class="o">-</span><span class="n">osd</span><span class="o">-</span><span class="n">ldiskfs</span><span class="o">-</span><span class="mf">2.9</span><span class="o">.</span><span class="mi">52</span><span class="n">_60_g1d2fbad_dirty</span><span class="o">-</span><span class="mi">1</span><span class="o">.</span><span class="na">el7</span><span class="o">.</span><span class="na">centos</span><span class="o">.</span><span class="na">ppc64le</span>
    <span class="n">sg3_utils</span> <span class="k">is</span> <span class="n">needed</span> <span class="n">by</span> <span class="n">lustre</span><span class="o">-</span><span class="n">iokit</span><span class="o">-</span><span class="mf">2.9</span><span class="o">.</span><span class="mi">52</span><span class="n">_60_g1d2fbad_dirty</span><span class="o">-</span><span class="mi">1</span><span class="o">.</span><span class="na">el7</span><span class="o">.</span><span class="na">centos</span><span class="o">.</span><span class="na">ppc64le</span>
        <span class="n">attr</span> <span class="k">is</span> <span class="n">needed</span> <span class="n">by</span> <span class="n">lustre</span><span class="o">-</span><span class="n">tests</span><span class="o">-</span><span class="mf">2.9</span><span class="o">.</span><span class="mi">52</span><span class="n">_60_g1d2fbad_dirty</span><span class="o">-</span><span class="mi">1</span><span class="o">.</span><span class="na">el7</span><span class="o">.</span><span class="na">centos</span><span class="o">.</span><span class="na">ppc64le</span>
        <span class="n">lsof</span> <span class="k">is</span> <span class="n">needed</span> <span class="n">by</span> <span class="n">lustre</span><span class="o">-</span><span class="n">tests</span><span class="o">-</span><span class="mf">2.9</span><span class="o">.</span><span class="mi">52</span><span class="n">_60_g1d2fbad_dirty</span><span class="o">-</span><span class="mi">1</span><span class="o">.</span><span class="na">el7</span><span class="o">.</span><span class="na">centos</span><span class="o">.</span><span class="na">ppc64le</span>
</pre></div>


<p>I was able to install <code>sg3_utils</code>, <code>attr</code> and <code>lsof</code>, but I was still missing <code>ldiskfsprogs</code>.</p>
<p>It seems we need the lustre-patched version of <code>e2fsprogs</code> - I found a <a href="https://groups.google.com/forum/#!topic/lustre-discuss-list/U93Ja6Xkxfk">mailing list post</a> to that effect.</p>
<p>So, following the instructions on the walkthrough, I grabbed <a href="https://downloads.hpdd.intel.com/public/e2fsprogs/latest/el7/SRPMS/">the SRPM</a> and installed the dependencies: <code>yum install -y texinfo libblkid-devel libuuid-devel</code></p>
<p>I then tried <code>rpmbuild -ba SPECS/e2fsprogs-RHEL-7.spec</code>. This built but failed tests. Some failed because I ran out of disk space - they were using 10s of gigabytes. I found that there were some comments in the spec file about this with suggested tests to disable, so I did that. Even with that fix, I was still failing two tests:</p>
<ul>
<li><code>f_pgsize_gt_blksize</code>: Intel added this to their fork, and no equivalent exists in the master e2fsprogs branches. This relates to Intel specific assumptions about page sizes which don't hold on Power.</li>
<li><code>f_eofblocks</code>: This may need fixing for large page sizes, see <a href="https://jira.hpdd.intel.com/browse/LU-4677?focusedCommentId=78814&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-78814">this bug</a>.</li>
</ul>
<p>I disabled the tests by adding the following two lines to the spec file, just before <code>make %{?_smp_mflags} check</code>.</p>
<div class="highlight"><pre><span></span>rm -rf tests/f_pgsize_gt_blksize
rm -rf tests/f_eofblocks
</pre></div>


<p>With those tests disabled I was able to build the packages successfully. I installed them with <code>yum localinstall *1.42.13.wc5*</code> (I needed that rather weird pattern to pick up important RPMs that didn't fit the <code>e2fs*</code> pattern - things like <code>libcom_err</code> and <code>libss</code>)</p>
<p>Following that I went back to the <code>lustre-release</code> build products and was able to successfully run <code>yum localinstall *ppc64le.rpm</code>!</p>
<h1>Testing the server</h1>
<p>After disabling SELinux and rebooting, I ran the test script:</p>
<div class="highlight"><pre><span></span>sudo /usr/lib64/lustre/tests/llmount.sh
</pre></div>


<p>This spat out one scary warning:</p>
<div class="highlight"><pre><span></span>mount.lustre FATAL: unhandled/unloaded fs type 0 &#39;ext3&#39;
</pre></div>


<p>The test did seem to succeed overall, and it would seem that is a <a href="https://jira.hpdd.intel.com/browse/LU-9059">known problem</a>, so I pressed on undeterred.</p>
<p>I then attached a couple of virtual harddrives for the metadata and object store volumes, and having set them up, proceeded to try to mount my freshly minted lustre volume from some clients.</p>
<h1>Testing with a ppc64le client</h1>
<p>My first step was to test whether another ppc64le machine would work as a client.</p>
<p>I tried with an existing Ubuntu 16.04 VM that I use for much of my day to day development.</p>
<p>A quick google suggested that I could grab the <code>lustre-release</code> repository and run <code>make debs</code> to get Debian packages for my system.</p>
<p>I needed the following dependencies:</p>
<div class="highlight"><pre><span></span>sudo apt install module-assistant debhelper dpatch libsnmp-dev quilt
</pre></div>


<p>With those the packages built successfully, and could be easily installed:</p>
<div class="highlight"><pre><span></span>dpkg -i lustre-client-modules-4.4.0-57-generic_2.9.52-60-g1d2fbad-dirty-1_ppc64el.deblustre-utils_2.9.52-60-g1d2fbad-dirty-1_ppc64el.deb
</pre></div>


<p>I tried to connect to the server:</p>
<div class="highlight"><pre><span></span>sudo mount -t lustre $SERVER_IP@tcp:/lustre /lustre/
</pre></div>


<p>Initially I wasn't able to connect to the server at all. I remembered that (unlike Ubuntu), CentOS comes with quite an aggressive firewall by default. I ran the following on the server:</p>
<div class="highlight"><pre><span></span>systemctl stop firewalld
</pre></div>


<p>And voila! I was able to connect, mount the lustre volume, and successfully read and write to it. This is very much an over-the-top hack - I should have poked holes in the firewall to allow just the ports lustre needed. This is left as an exercise for the reader.</p>
<h1>Testing with an x86_64 client</h1>
<p>I then tried to run <code>make debs</code> on my Ubuntu 16.10 x86_64 laptop.</p>
<p>This did not go well - I got the following error:</p>
<div class="highlight"><pre><span></span>liblustreapi.c: In function ‘llapi_get_poollist’:
liblustreapi.c:1201:3: error: ‘readdir_r’ is deprecated [-Werror=deprecated-declarations]
</pre></div>


<p>This looks like one of the new errors introduced in recent GCC versions, and is <a href="https://jira.hpdd.intel.com/browse/LU-8724?focusedCommentId=175244&amp;page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-175244">a known bug</a>. To work around it, I found the following stanza in a <code>lustre/autoconf/lustre-core.m4</code>, and removed the <code>-Werror</code>:</p>
<div class="highlight"><pre><span></span>AS_IF([test $target_cpu == &quot;i686&quot; -o $target_cpu == &quot;x86_64&quot;],
        [CFLAGS=&quot;$CFLAGS -Wall -Werror&quot;])
</pre></div>


<p>Even this wasn't enough: I got the following errors:</p>
<div class="highlight"><pre><span></span>/home/dja/dev/lustre-release/debian/tmp/modules-deb/usr_src/modules/lustre/lustre/llite/dcache.c:387:22: error: initialization from incompatible pointer type [-Werror=incompatible-pointer-types]
         .d_compare = ll_dcompare,
                  ^~~~~~~~~~~
/home/dja/dev/lustre-release/debian/tmp/modules-deb/usr_src/modules/lustre/lustre/llite/dcache.c:387:22: note: (near initialization for ‘ll_d_ops.d_compare’)
</pre></div>


<p>I figured this was probably because Ubuntu 16.10 has a 4.8 kernel, and Ubuntu 16.04 has a 4.4 kernel. Work on supporting 4.8 <a href="https://jira.hpdd.intel.com/browse/LU-9003">is ongoing</a>.</p>
<p>Sure enough, when I fired up a 16.04 x86_64 VM with a 4.4 kernel, I was able to build and install fine.</p>
<p>Connecting didn't work first time - the guest failed to mount, but I did get the following helpful error on the server:</p>
<div class="highlight"><pre><span></span><span class="n">LNetError</span><span class="o">:</span> <span class="mi">2595</span><span class="o">:</span><span class="mi">0</span><span class="o">:(</span><span class="n">acceptor</span><span class="o">.</span><span class="na">c</span><span class="o">:</span><span class="mi">406</span><span class="o">:</span><span class="n">lnet_acceptor</span><span class="o">())</span> <span class="n">Refusing</span> <span class="n">connection</span> <span class="n">from</span> <span class="mf">10.61</span><span class="o">.</span><span class="mf">2.227</span><span class="o">:</span> <span class="n">insecure</span> <span class="n">port</span> <span class="mi">1024</span>
</pre></div>


<p>Refusing insecure port 1024 made me thing that perhaps the NATing that qemu was performing for me was interfering - perhaps the server expected to get a connection where the source port was privileged, and qemu wouldn't be able to do that with NAT.</p>
<p>Sure enough, switching NAT to bridging was enough to get the x86 VM to talk to the ppc64le server. I verified that <code>ls</code>, reading and writing all succeeded.</p>
<h1>Next steps</h1>
<p>The obvious next steps are following up the disabled tests in e2fsprogs, and doing a lot of internal performance and functionality testing.</p>
<p>Happily, it looks like Lustre might be in the mainline kernel before too long - parts have already started to go in to staging. This will make our lives a lot easier: for example, the breakage between 4.4 and 4.8 would probably have already been picked up and fixed if it was the main kernel tree rather than an out-of-tree patch set.</p>
<p>In the long run, we'd like to make Lustre on Power just as easy as Lustre on x86. (And, of course, more performant!) We'll keep you up to date!</p>
<p>(Thanks to fellow bloggers Daniel Black and Andrew Donnellan for useful feedback on this post.)</p>
  </div><!-- /.entry-content -->
</section>
        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>,
                which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->
        </footer><!-- /#contentinfo -->
</body>
</html>