<!DOCTYPE html>
<html lang="en">
<head>
        <title>Store Half Byte-Reverse Indexed</title>
        <meta charset="utf-8" />
        <link href="https://sthbrx.github.io/atom.xml" type="application/atom+xml" rel="alternate" title="Store Half Byte-Reverse Indexed Full Atom Feed" />
        <link href="https://sthbrx.github.io/rss.xml" type="application/rss+xml" rel="alternate" title="Store Half Byte-Reverse Indexed RSS Feed" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="https://sthbrx.github.io/">Store Half Byte-Reverse Indexed <strong>A Power Technical Blog</strong></a></h1>
        </header><!-- /#banner -->
        <nav id="menu"><ul>
        </ul></nav><!-- /#menu -->
<section id="content">
<h2>Articles in the Education category</h2>

<ol id="post-list">
        <li><article class="hentry">
                <header> <h2 class="entry-title"><a href="https://sthbrx.github.io/blog/2017/01/31/linuxconfau-2017-review/" rel="bookmark" title="Permalink to linux.conf.au 2017 review">linux.conf.au 2017 review</a></h2> </header>
                <footer class="post-info">
                    <time class="published" datetime="2017-01-31T16:07:00+11:00"> Tue 31 January 2017 </time>
                    <address class="vcard author">By
                        <a class="url fn" href="https://sthbrx.github.io/author/daniel-axtens.html">Daniel Axtens</a>
                    </address>
                </footer><!-- /.post-info -->
                <div class="entry-content"> <p>I recently attended LCA 2017, where I gave a talk at the Linux Kernel miniconf (run by fellow sthbrx blogger Andrew Donnellan!) and a talk at the main conference.</p>
<p>I received some really interesting feedback so I've taken the opportunity to write some of it down to complement the talk videos and slides that are online. (And to remind me to follow up on it!)</p>
<h2>Miniconf talk: Sparse Warnings</h2>
<p>My kernel miniconf talk was on sparse warnings (<a href="https://github.com/daxtens/sparse-warnings-talk/blob/master/talk.pdf">pdf slides</a>, <a href="https://www.youtube.com/watch?v=hmCukzpevUc">23m video</a>).</p>
<p>The abstract read (in part):</p>
<blockquote>
<p>sparse is a semantic parser for C, and is one of the static analysis tools available to kernel devs.</p>
<p>Sparse is a powerful tool with good integration into the kernel build system. However, we suffer from warning overload - there are too many sparse warnings to spot the serious issues amongst the trivial. This makes it difficult to use, both for developers and maintainers.</p>
</blockquote>
<p>Happily, I received some feedback that suggests it's not all doom and gloom like I had thought!</p>
<ul>
<li>
<p>Dave Chinner told me that the xfs team uses sparse regularly to make sure that the file system is endian-safe. This is good news - we really would like that to be endian-safe!</p>
</li>
<li>
<p>Paul McKenney let me know that the 0day bot does do some sparse checking - it would just seem that it's not done on PowerPC.</p>
</li>
</ul>
<h2>Main talk: 400,000 Ephemeral Containers</h2>
<p>My main talk was entitled "400,000 Ephemeral Containers: testing entire ecosystems with Docker". You can read the <a href="https://linux.conf.au/schedule/presentation/81/">abstract</a> for full details, but it boils down to:</p>
<blockquote>
<p>What if you want to test how <em>all</em> the packages in a given ecosystem work in a given situation?</p>
</blockquote>
<p>My main example was testing how many of the Ruby packages successfully install on Power, but I also talk about other languages and other cool tests you could run.</p>
<p>The <a href="https://www.youtube.com/watch?v=v7wSqOQeGhA">44m video</a> is online. I haven't put the slides up yet but they should be available <a href="https://github.com/daxtens/400000-ephemeral-containers">on GitHub</a> soonish.</p>
<p>Unlike with the kernel talk, I didn't catch the names of most of the people with feedback.</p>
<h3>Docker memory issues</h3>
<p>One of the questions I received during the talk was about running into memory issues in Docker. I attempted to answer that during the Q&amp;A. The person who asked the question then had a chat with me afterwards, and it turns out I had completely misunderstood the question. I thought it was about memory usage of running containers in parallel. It was actually about memory usage in the docker daemon when running lots of containers in serial. Apparently the docker daemon doesn't free memory during the life of the process, and the question was whether or not I had observed that during my runs.</p>
<p>I didn't have a good answer for this at the time other than "it worked for me", so I have gone back and looked at the docker daemon memory usage.</p>
<p>After a full Ruby run, the daemon is using about 13.9G of virtual memory, and 1.975G of resident memory. If I restart it, the memory usage drops to 1.6G of virtual and 43M of resident memory. So it would appear that the person asking the question was right, and I'm just not seeing it have an effect.</p>
<h3>Other interesting feedback</h3>
<ul>
<li>
<p>Someone was quite interested in testing on Sparc, once they got their Go runtime nailed down.</p>
</li>
<li>
<p>A Rackspacer was quite interested in Python testing for OpenStack - this has some intricacies around Py2/Py3, but we had an interesting discussion around just testing to see if packages that claim Py3 support provide Py3 support.</p>
</li>
<li>
<p>A large jobs site mentioned using this technique to help them migrate their dependencies between versions of Go.</p>
</li>
<li>
<p>I was 'gently encouraged' to try to do better with how long the process takes to run - if for no other reason than to avoid burning more coal. This is a fair point. I did not explain very well what I meant with diminishing returns in the talk: there's <em>lots</em> you could do to make the process faster, it's just comes at the cost of the simplicity that I really wanted when I first started the project. I am working (on and off) on better ways to deal with this by considering the dependency graph.</p>
</li>
</ul> </div><!-- /.entry-content -->
        </article></li>
        <li><article class="hentry">
                <header> <h2 class="entry-title"><a href="https://sthbrx.github.io/blog/2016/07/01/a-taste-of-ibm/" rel="bookmark" title="Permalink to A Taste of IBM">A Taste of IBM</a></h2> </header>
                <footer class="post-info">
                    <time class="published" datetime="2016-07-01T11:45:00+10:00"> Fri 01 July 2016 </time>
                    <address class="vcard author">By
                        <a class="url fn" href="https://sthbrx.github.io/author/rohan-mclure.html">Rohan McLure</a>
                    </address>
                </footer><!-- /.post-info -->
                <div class="entry-content"> <p>As a hobbyist programmer and Linux user, I was pretty stoked to be able to experience real work in the IT field that interests me most, Linux. With a mainly disconnected understanding of computer hardware and software, I braced myself to entirely relearn everything and anything I thought I knew. Furthermore, I worried that my usefulness in a world of maintainers, developers and testers would not be enough to provide any real contribution to the company. In actual fact however, the employees at OzLabs (IBM ADL) put a really great effort into making use of my existing skills, were attentive to my current knowledge and just filled in the gaps! The knowledge they've given me is practical, interlinked with hardware and provided me with the foot-up that I'd been itching for to establish my own portfolio as a programmer. I was both honoured and astonished by their dedication to helping me make a truly meaningful contribution!</p>
<p>On applying for the placement, I listed my skills and interests. Having a Mathematics, Science background, I listed among my greatest interests development of scientific simulation and graphics using libraries such as Python matplotlib and R. By the <em>first day</em> they got me to work, researching and implementing a routine in R that would qualitatively model the ability of a system to perform common tasks - a benchmark. A series of these microbenchmarks were made; I was in my element and actually able to contribute to a corporation much larger than I could imagine. The team at IBM reinforced my knowledge from the ground up, introducing the rigorous hardware and corporate elements at a level I was comfortable with.</p>
<p>I would say that my greatest single piece of take-home knowledge over the two weeks was knowledge of the Linux Kernel project, Git and GitHub. Having met the arch/powerpc and linux-next maintainers in person placed the Linux and Open Source development cycle in an entirely new perspective. I was introduced to the world of GitHub, and thanks to a few rigorous lessons of Git, I now have access to tools that empower me to safely and efficiently write code, and to build a public portfolio I can be proud of. Most members of the office donated their time to instruct me on all fronts, whether to do with career paths, programming expertise or conceptual knowledge, and the rest were all very good for a chat.</p>
<p>Approaching the tail-end of Year Twelve, I was blessed with some really good feedback and recommendations regarding further study. If during the two weeks I had any query regarding anything ranging from work-life to programming expertise even to which code editor I should use (a source of much contention) the people in the office were very happy to help me. Several employees donated their time to teach me really very intensive and long lessons regarding the software development concepts, including (but not limited to!) a thorough and helpful lesson on Git that was just on my level of understanding.</p>
<p>Working at IBM these past two weeks has not only bridged the gap between my hobby and my professional prospects, but more importantly established friendships with professionals in the field of Software Development. Without a doubt this really great experience of an environment that rewards my enthusiasm will fondly stay in my mind as I enter the next chapter of my life!</p> </div><!-- /.entry-content -->
        </article></li>
        <li><article class="hentry">
                <header> <h2 class="entry-title"><a href="https://sthbrx.github.io/blog/2016/06/08/interning-at-ozlabs/" rel="bookmark" title="Permalink to Interning at Ozlabs">Interning at Ozlabs</a></h2> </header>
                <footer class="post-info">
                    <time class="published" datetime="2016-06-08T22:22:00+10:00"> Wed 08 June 2016 </time>
                    <address class="vcard author">By
                        <a class="url fn" href="https://sthbrx.github.io/author/rashmica-gupta.html">Rashmica Gupta</a>
                    </address>
                </footer><!-- /.post-info -->
                <div class="entry-content"> <p>I am sadly coming to the end of my six(ish) month internship with Ozlabs (funded by <a href="https://www.acs.org.au">ACS</a>). So here I am writing about my experience in the hopes that future prospective interns can read about how they should come and work with the previously dubbed Linux Gods.</p>
<h3>What is your background?</h3>
<p>Despite embracing being a nerd at school, my opinion of computers prior to starting my Engineering degree was that they were boring and for geeky boys who didn't want to interact with the 'real' world. However when having to choose a specialisation of Engineering I was drawn towards Computer Systems as everything else seemed obvious * but Computer Systems was this great mystical unknown. </p>
<p>Fast forward three years, and I had seen glimpses into the workings of this magical computer world. I had learnt about transistors, logic gates and opamps; I had designed circuits that actually worked; and I had bashed my head against a wall trying to find obscure bugs. I had dabbled in a range of languages from the low levels of VHDL and embedded C, to the abstract world of Python and Java and delved into the obscure world of declarative prologs and relational reinforcement learning. Now it was time to solidify some of these concepts and get some experience under my belt so I could feel less like a monkey bashing random keys on my keyboard. Enter Ozlabs!</p>
<h3>What did you do at Ozlabs?</h3>
<p>After being handed a nice laptop and the root passwords, I faced the inevitable battle of getting everything setup. With the help of my mentor, the prestigious <a href="http://mpe.github.io/">Michael Ellerman</a>, and various other Ozlabs residents I picked off some low hanging fruit such as removing unused code and tidying up a few things. This allowed me to get familiar with the open-source workflow, the kernel building process, IRC, do more with Git then just push and pull, and <strong>finally</strong> come face-to-face with the seemingly impossible: Vim and virtual machines.</p>
<p>I then got to learn about Transactional Memory (TM) - a way of making a bunch of instructions on one processor appear to be one atomic operation to other processors. I took some old TM tests from Mikey and checked that they did indeed pass and fail when they were supposed to and refurbished them a little, learning how to run kernel self-tests and a bit about powerpc assembly along the way.</p>
<p>Eventually my fear of shell scripts was no match for my desire to be able to build and install a kernel with one command and so I finally got around to writing a build script. Accidentally rebooting a bare-metal machine instead of my VM running on it may have had a significant contribution to this...</p>
<p>The next interesting task I got to tackle was to implement a virtual memory dump that other architectures like x86 have, so we can see how the pages in memory are laid out along with information about these pages. This involved understanding x86's implementation and relating that to POWER's memory management. At Uni I never quite understood the fuss about pages and virtual memory and so it was great to be able to build up an appreciation and play around with page tables, virtual to real addresses, and hashtable.</p>
<p>I then moved onto <a href="https://sthbrx.github.io/blog/2016/05/13/srop-mitigation/">SROP mitigation</a>! After a lot of reading and re-reading, I decided to first understand how to use SROP to make an exploit on POWER which meant some assembly, diving into the signal code and finally meeting and spending time with GDB.  Once again I had x86 code to port over to POWER, the main issue being making sure that I didn't break existing things - aka hours and hours of running the kernel self-tests and the Linux Test Project tests and some more scripting, with the help of <a href="http://blog.christophersmart.com/">Chris Smart</a>, to collate the results.</p>
<p>You can judge all my submitted patches <a href="https://patchwork.ozlabs.org/project/linuxppc-dev/list/?submitter=67695&amp;state=*">here</a>.</p>
<h3>What was your overall experience like at Ozlabs?</h3>
<p>I moved to Canberra shortly after finishing exams and so hadn't had the time to ponder expectations of Ozlabs. Everyone was super friendly and despite being, not just the only female but, the only kiwi among a whoooole lot of Aussies I experienced a distinct lack of discrimination (apart from a bit of banter about accents).</p>
<p>Could I wear my normal clothes (and not stuffy business clothes)? Check. Did I get to work on interesting things? Check. Could I do my work without having to go through lots of unnecessary hoops and what not? Check. Could I develop my own workflow and learn all the things? Check. Did I get to delve into a few different areas? Check. Was I surrounded by super smart people who were willing to help me learn? Check. </p>
<p>All in all, I have had a great time here, learnt so much and you should definitely come and work at Ozlabs! Hopefully you'll see me back on this blog in a few months :)</p>
<p>* <em>My pre-university, perhaps somewhat naiive, opinion: Civil and Mechanical is just physics. Chemical and Materials is just chemistry. Electrical seems interesting but who wants to work with power lines? Biomedical is just math and biology. Software is just abstract high level nonsense. But how a computer works?? That is some magical stuff.</em></p> </div><!-- /.entry-content -->
        </article></li>
        <li><article class="hentry">
                <header> <h2 class="entry-title"><a href="https://sthbrx.github.io/blog/2016/05/12/doubles-in-hex-and-why-kernel-addresses-2/" rel="bookmark" title="Permalink to Doubles in hex and why Kernel addresses ~= -2">Doubles in hex and why Kernel addresses ~= -2</a></h2> </header>
                <footer class="post-info">
                    <time class="published" datetime="2016-05-12T22:22:00+10:00"> Thu 12 May 2016 </time>
                    <address class="vcard author">By
                        <a class="url fn" href="https://sthbrx.github.io/author/suraj-jitindar-singh.html">Suraj Jitindar Singh</a>
                    </address>
                </footer><!-- /.post-info -->
                <div class="entry-content"> <p>It started off a regular Wednesday morning when I hear from my desk a colleague
muttering about doubles and their hex representation. "But that doesn't look
right", "How do I read this as a float", and "<del>redacted</del> you're the engineer,
you do it". My interest piqued, I headed over to his desk to enquire about the
great un-solvable mystery of the double and its hex representation. The number
which would consume me for the rest of the morning: 0xc00000001568fba0.</p>
<h2>That's a Perfectly Valid hex Number!</h2>
<p>I hear you say. And you're right, if we were to treat this as a long it
would simply be 13835058055641365408 (or -4611686018068186208 if we assume
a signed value). But we happen to know that this particular piece of data which
we have printed is supposed to represent a double (-2 to be precise). "Well
print it as a double" I hear from the back, and once again we <em>should</em> all know
that this can be achieved rather easily by using the %f/%e/%g specifiers in our
print statement. The only problem is that in kernel land (where we use printk)
we are limited to printing fixed point numbers, hence why our only <em>easy</em>
option was to print our double in it's raw hex format.</p>
<p>This is the point where we all think back to that university course where
number representations were covered in depth, and terms like 'mantissa' and
'exponent' surface in our minds. Of course as we rack our brains we realise
there's no way that we're going to remember exactly how a double is represented
and bring up the <a href="https://en.wikipedia.org/wiki/Double-precision_floating-point_format">IEEE 754 Wikipedia page</a>.</p>
<h2>What is a Double?</h2>
<p>Taking a step back for a second, a double (or a double-precision floating-point)
is a number format used to represent floating-point numbers (those with a
decimal component). They are made up of a sign bit, an exponent and a fraction
(or mantissa):</p>
<p><img alt="Double Format" src="/images/surajjs/doubles_in_hex/double.png"></p>
<p>Where the number they represent is defined by:</p>
<p><img alt="Double Formula" src="/images/surajjs/doubles_in_hex/formula.png"></p>
<p>So this means that a 1 in the MSB (sign bit) represents a negative number, and
we have some decimal component (the fraction) which we multiply by some power
of 2 (as determined by the exponent) to get our value.</p>
<h2>Alright, so what's 0xc00000001568fba0?</h2>
<p>The reason we're all here to be begin with, so what's 0xc00000001568fba0 if we
treat it as a double? We can first split it into the three components:</p>
<h5>0xc00000001568fba0:</h5>
<p>Sign bit: 1             -&gt; Negative<br>
Exponent: 0x400         -&gt; 2<sup>(1024 - 1023)</sup><br>
Fraction: 0x1568fba0    -&gt; 1.<em>something</em><br></p>
<p>And then use the formula above to get our number:</p>
<p>(-1)<sup><strong>1</strong></sup> x 1.<em><strong>something</strong></em> x 2<sup><strong>(1024 - 1023)</strong></sup></p>
<p><strong>But there's a much easier way!</strong> Just write ourselves a little program in
userspace (where we are capable of printing floats) and we can save ourselves
<em>most</em> of the trouble.</p>
<div class="highlight"><pre><span></span><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp"></span>

<span class="kt">void</span> <span class="nf">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">long</span> <span class="n">val</span> <span class="o">=</span> <span class="mh">0xc00000001568fba0</span><span class="p">;</span>

    <span class="n">printf</span><span class="p">(</span><span class="s">&quot;val: %lf</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="o">*</span><span class="p">((</span><span class="kt">double</span> <span class="o">*</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">val</span><span class="p">));</span>
<span class="p">}</span>
</pre></div>


<p>So all we're doing is taking our hex value and storing it in a long (val), then
getting a pointer to val, casting it to a double pointer, and dereferencing it
and printing it as a float. <em><strong>Drum Roll</strong></em> And the answer is?</p>
<blockquote>
<p>"val: -2.000000"</p>
</blockquote>
<p>"Wait a minute, that doesn't quite sound right". You're right, it does seem a
bit strange that this is exactly -2. Well it may be that we are not printing
enough decimal places to see the full result, so update our print statement to:</p>
<div class="highlight"><pre><span></span><span class="n">printf</span><span class="p">(</span><span class="s">&quot;val: %.64lf</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="o">*</span><span class="p">((</span><span class="kt">double</span> <span class="o">*</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">val</span><span class="p">));</span>
</pre></div>


<p>And now we get:</p>
<blockquote>
<p>"val: -2.0000001595175973534423974342644214630126953125000000"</p>
</blockquote>
<p>Much better... But still where did this number come from and why wasn't it the
-2 that we were expecting?</p>
<h2>Kernel Pointers</h2>
<p>At this point suspicions had been raised that what was being printed by my
colleague was not what he expected and that this was in fact a Kernel pointer.
How do you know? Lets take a step back for a second...</p>
<p>In the PowerPC architecture, the address space which can be seen by an
application is known as the <em>effective</em> address space. We can take this
and translate it into a <em>virtual</em> address which when mapped through the
HPT (hash page table) gives us a <em>real</em> address (or the hardware memory address).</p>
<p>The <em>effective</em> address space is divided into 5 regions:</p>
<p><img alt="Effective Address Table" src="/images/surajjs/doubles_in_hex/effective_address.png"></p>
<p>As you may notice, Kernel addresses begin with 0xc. This has the advantage that
we can map a <em>virtual</em> address without the need for a table by simply
masking the top nibble.</p>
<p>Thus it would be reasonable to assume that our value (0xc00000001568fba0) was
indeed a pointer to a Kernel address (and further code investigation confirmed
this).</p>
<h2>But What is -2 as a Double in hex?</h2>
<p>Well lets modify the above program and find out:</p>
<div class="highlight"><pre><span></span><span class="n">include</span> <span class="o">&lt;</span><span class="n">stdio</span><span class="p">.</span><span class="n">h</span><span class="o">&gt;</span>

<span class="kt">void</span> <span class="n">main</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span>
<span class="p">{</span>
        <span class="kt">double</span> <span class="n">val</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="p">;</span>

        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;val: 0x%lx</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="o">*</span><span class="p">((</span><span class="kt">long</span> <span class="o">*</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">val</span><span class="p">));</span>
<span class="p">}</span>
</pre></div>


<p>Result?</p>
<blockquote>
<p>"val: 0xc000000000000000"</p>
</blockquote>
<p>Now that sounds much better. Lets take a closer look:</p>
<h5>0xc000000000000000:</h5>
<p>Sign Bit: 1     -&gt; Negative<br>
Exponent: 0x400 -&gt; 2<sup>(1024 - 1023)</sup><br>
Fraction: 0x0   -&gt; Zero<br></p>
<p>So if you remember from above, we have:</p>
<p>(-1)<sup><strong>1</strong></sup> x 1.<em><strong>0</strong></em> x 2<sup><strong>(1024 - 1023)</strong></sup> = -2</p>
<p>What about -1? -3?</p>
<h4>-1:</h4>
<h5>0xbff0000000000000:</h5>
<p>Sign Bit: 1     -&gt; Negative<br>
Exponent: 0x3ff -&gt; 2<sup>(1023 - 1023)</sup><br>
Fraction: 0x0   -&gt; Zero<br></p>
<p>(-1)<sup><strong>1</strong></sup> x 1.<em><strong>0</strong></em> x 2<sup><strong>(1023 - 1023)</strong></sup> = -1</p>
<h4>-3:</h4>
<h5>0xc008000000000000:</h5>
<p>Sign Bit: 1                     -&gt; Negative<br>
Exponent: 0x400                 -&gt; 2<sup>(1024 - 1023)</sup><br>
Fraction: 0x8000000000000       -&gt; 0.5<br></p>
<p>(-1)<sup><strong>1</strong></sup> x 1.<em><strong>5</strong></em> x 2<sup><strong>(1024 - 1023)</strong></sup> = -3</p>
<h2>So What Have We Learnt?</h2>
<p><strong>Firstly</strong>, make sure that what you're printing is what you think you're printing.</p>
<p><strong>Secondly</strong>, if it looks like a Kernel pointer then you're probably not printing
what you think you're printing.</p>
<p><strong>Thirdly</strong>, all Kernel pointers ~= -2 if you treat them as a double.</p>
<p>And <strong>Finally</strong>, <em>with my morning gone</em>, I can say for certain that if we treat it as
a double, 0xc00000001568fba0 =
-2.0000001595175973534423974342644214630126953125.</p> </div><!-- /.entry-content -->
        </article></li>
        <li><article class="hentry">
                <header> <h2 class="entry-title"><a href="https://sthbrx.github.io/blog/2016/03/15/and-now-for-something-completely-different-approximate-computing/" rel="bookmark" title="Permalink to And now for something completely different: approximate computing">And now for something completely different: approximate computing</a></h2> </header>
                <footer class="post-info">
                    <time class="published" datetime="2016-03-15T11:30:00+11:00"> Tue 15 March 2016 </time>
                    <address class="vcard author">By
                        <a class="url fn" href="https://sthbrx.github.io/author/daniel-axtens.html">Daniel Axtens</a>
                    </address>
                </footer><!-- /.post-info -->
                <div class="entry-content"> <p>In early February I had the opportunity to go the the NICTA Systems Summer School, where Cyril and I were invited to represent IBM. There were a number of excellent talks across a huge range of systems related subjects, but the one that has stuck with me the most was a talk given by <a href="http://homes.cs.washington.edu/~luisceze/">Luis Ceze</a>  on a topic called approximate computing. So here, in hopes that you too find it interesting, is a brief run-down on what I learned.</p>
<p>Approximate computing is fundamentally about trading off accuracy for something else - often speed or power consumption. Initially this sounded like a very weird proposition: computers do things like 'running your operating system' and 'reading from and writing to disks': things you need to always be absolutely correct if you want anything vaguely resembling reliability. It turns out that this is actually not as big a roadblock as I had assumed - you can work around it fairly easily.</p>
<p>The model proposed for approximate computing is as follows. You divide your computation up into two classes: 'precise', and 'approximate'. You use 'precise' computations when you need to get exact answers: so for example if you are constructing a JPEG file, you want the JPEG header to be exact. Then you have approximate computations: so for example the contents of your image can be approximate.</p>
<p>For correctness, you have to establish some boundaries: you say that precise data can be used in approximate calculations, but that approximate data isn't allowed to cross back over and pollute precise calculations. This, while intuitively correct, poses some problems in practise: when you want to write out your approximate JPEG data, you need an operation that allows you to 'bless' (or in their terms 'endorse') some approximate data so it can be used in the precise file system operations.</p>
<p>In the talk we were shown an implementation of this model in Java, called <a href="http://sampa.cs.washington.edu/research/approximation/enerj.html">EnerJ</a>. EnerJ allows you to label variables with either <code>@Precise</code> if you're dealing with precise data, or <code>@Approx</code> if you're dealing with approximate data. The compiler was modified so that it would do all sorts of weird things when it knew it was dealing with approximate data: for example, drop loop iterations entirely, do things in entirely non-determistic ways - all sorts of fun stuff. It turns out this works surprisingly well.</p>
<p>However, the approximate computing really shines when you can bring it all the way down to the hardware level. The first thing they tried was a CPU with both 'approximate' and precise execution engines, but this turned out not to have the power savings hoped for. What seemed to work really well was a model where some approximate calculations could be identified ahead of time, and then replaced with neural networks in hardware. These neural networks approximated the calculations, but did so at significantly lower power levels. This sounded like a really promising concept, and it will be interesting to see if this goes anywhere over the next few years.</p>
<p>There's a lot of work evaluating the quality of the approximate result, for cases where the set of inputs is known, and when the inputs is not known. This is largely beyond my understanding, so I'll simply refer you to some of the papers <a href="http://sampa.cs.washington.edu/research/approximation/enerj.html">listed on the website</a>.</p>
<p>The final thing covered in the talk was bringing approximate computing into current paradigms by just being willing to accept higher user-visible error rates. For example, they hacked up a network stack to accept packets with invalid checksums. This has had mixed results so far. A question I had (but didn't get around to asking!) would be whether the mathematical properties of checksums (i.e. that they can correct a certain number of bit errors) could be used to correct some of the errors, rather than just accepting/rejecting them blindly. Perhaps by first attempting to correct errors using the checksums, we will be able to fix the simpler errors, reducing the error rate visible to the user.</p>
<p>Overall, I found the NICTA Systems Summer School to be a really interesting experience (and I hope to blog more about it soon). If you're a university student in Australia, or an academic, see if you can make it in 2017!</p> </div><!-- /.entry-content -->
        </article></li>
</ol><!-- /#posts-list -->
<p class="paginator">
    Page 1 / 2
        <a href="https://sthbrx.github.io/category/education2.html">&raquo;</a>
</p>
</section><!-- /#content -->
        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>,
                which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->
        </footer><!-- /#contentinfo -->
</body>
</html>